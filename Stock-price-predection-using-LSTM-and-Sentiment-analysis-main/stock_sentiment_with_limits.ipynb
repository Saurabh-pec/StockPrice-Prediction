{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arpit0891/Stock-Prediction-Using-Twitter-Sentiment-Analysis/blob/main/stock_sentiment_with_limits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PCH9DpEyAggq"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gH7WBS35Aggs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import subjectivity\n",
        "from nltk.sentiment import SentimentAnalyzer\n",
        "from nltk.sentiment.util import *\n",
        "import matplotlib.pyplot as mlpt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5J7kNKbXAggs"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tweetpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\SAURABH\\Desktop\\Final Year Project\\testing\\Stock-price-predection-using-LSTM-and-Sentiment-analysis-main\\stock_sentiment_with_limits.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/SAURABH/Desktop/Final%20Year%20Project/testing/Stock-price-predection-using-LSTM-and-Sentiment-analysis-main/stock_sentiment_with_limits.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtweetpy\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SAURABH/Desktop/Final%20Year%20Project/testing/Stock-price-predection-using-LSTM-and-Sentiment-analysis-main/stock_sentiment_with_limits.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SAURABH/Desktop/Final%20Year%20Project/testing/Stock-price-predection-using-LSTM-and-Sentiment-analysis-main/stock_sentiment_with_limits.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tweetpy'"
          ]
        }
      ],
      "source": [
        "import tweetpy\n",
        "import csv\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD_v5dTJAggs"
      },
      "outputs": [],
      "source": [
        "consumer_key    = '0HwwLndFzphxpc0FtcbTL1FHB'\n",
        "consumer_secret = '9s0bWRPf99KNseJUtaWRw2XFBVfyvizGEtO2OpSlDm7AcArSaF'\n",
        "\n",
        "access_token  = '1182380009215840256-5h6QC18s7vaOzMN51mnN0sjKCshbBg'\n",
        "access_token_secret = 'F1A2XGx3C0FXFK6AIRBFRQDmnkP3KOBYxWCiGgUz4dVek'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnSrq_ihAggt"
      },
      "outputs": [],
      "source": [
        "fetch_tweets=tweepy.Cursor(api.search, q=\"#sbin\",count=10000, lang =\"en\",since=\"2020-09-30\",until=\"2020-11-27\", tweet_mode=\"extended\").items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8h3ozKDAggt"
      },
      "outputs": [],
      "source": [
        "data=pd.DataFrame(data=[[tweet_info.created_at.date(),tweet_info.full_text]for tweet_info in fetch_tweets],columns=['Date','Tweets'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNBO8sumAggt",
        "outputId": "7c69377c-40cc-4013-ffbc-96839f8edeeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          Date                                             Tweets\n",
            "0   2020-11-26  Love hearing this everyday before the trading ...\n",
            "1   2020-11-26  Superbb calls provided by my mentor @CArajievv...\n",
            "2   2020-11-26  Today except #sbin my regular trade and #nifty...\n",
            "3   2020-11-26  @shail_bhatnagar @CNBC_Awaaz @CNBCBajar @heman...\n",
            "4   2020-11-26  Buy 2 CURMON #SBIN contracts at 242.95, Sell 3...\n",
            "5   2020-11-26  Buy 2 CURMON #SBIN contracts at 242.95, Sell 3...\n",
            "6   2020-11-26  RT @mohit_maxmoh: #SBIN CMP 244.1 Tommorow is ...\n",
            "7   2020-11-26  #SBIN CMP 244.1 Tommorow is weekly close and a...\n",
            "8   2020-11-26  #SBIN CMP 243.4 Reversing on hourly charts htt...\n",
            "9   2020-11-26  SBIN - EQ\\n\\nBuy Above247.00with SL Below241.0...\n",
            "10  2020-11-26  RT @shivaji_1983: Similarities between 2014 &a...\n",
            "11  2020-11-25  #SBIN \\n\\nLuxury car maker Mercedes-Benz India...\n",
            "12  2020-11-25  Booked profit in #banknifty and #nifty...... R...\n",
            "13  2020-11-25  Buy 1 CURMON #SBIN contracts at 242.45, Sell 2...\n",
            "14  2020-11-25  #investment / SHORT TERM #NSE\\nBUY #SBIN cmp 2...\n",
            "15  2020-11-25  #SBIN\\n\\nHigh for this series\\n\\n253\\n\\nRollov...\n",
            "16  2020-11-25  #SBIN out at 246.5\\n\\n#LiveTrades #Intraday #D...\n",
            "17  2020-11-25  #SBIN\\nSBIN in Moving in Bharti way\\n158 &gt;&...\n",
            "18  2020-11-25  #SBIN\\nSBIN in Moving in Bharti way\\n158 &gt;&...\n",
            "19  2020-11-25  #SBIN short at 244.6\\n\\n#LiveTrades #Intraday ...\n",
            "20  2020-11-25  #SBIN exit 246.1\\n\\n#LiveTrades #Intraday #Day...\n",
            "21  2020-11-25  #SBIN shorted at 245.2\\n\\n#LiveTrades #Intrada...\n",
            "22  2020-11-25  Ok, #SBIN moving now.\\n\\n#LiveTrades #Intraday...\n",
            "23  2020-11-25  #sbin\\nToday giving nice swing both side..\\nNo...\n",
            "24  2020-11-25  Buy 1 CURMON #SBIN contracts at 243.45, Sell 2...\n",
            "25  2020-11-25  #SBIN - SBIN LONG - TradingView - https://t.co...\n",
            "26  2020-11-25  State Bank India target has been reached #Shor...\n",
            "27  2020-11-25  #SBIN \\nDelivery Buy Call \\nCmp          248.5...\n",
            "28  2020-11-25  Nifty50 trade above 13,100. Nifty Bank 30000+ ...\n",
            "29  2020-11-25  #SBIN #RBLBANK #IBULHSGFIN BULLISH, BUY IN DIP...\n",
            "30  2020-11-24  #SBIN - Another trade of the day.  \\n\\n#PriceA...\n",
            "31  2020-11-24  #PSU #Banks Ignored in this  Uptrend rally but...\n",
            "32  2020-11-24  RT @shivaji_1983: Similarities between 2014 &a...\n",
            "33  2020-11-24                 #sbin too confirms buy signal @243\n",
            "34  2020-11-24  Top 7 Banks in India \\n\\nFollow us on @iifsind...\n",
            "35  2020-11-24  Buy 9 CURMON #BANKBARODA contracts at 46, Sell...\n",
            "36  2020-11-24  Do u agree for broad based stocks rally #relia...\n",
            "37  2020-11-24  Buy 9 CURMON #BANKBARODA contracts at 45.95, S...\n",
            "38  2020-11-24  Huge Up move possible in coming days positiona...\n",
            "39  2020-11-23  RT @TechnomanThe: SBI Apprentice Recruitment 2...\n",
            "40  2020-11-23  State Bank Of India Now on Wave C  - #SBIN cha...\n",
            "41  2020-11-23  #SBIN &amp; #Axis closed !! https://t.co/yt1Xt...\n",
            "42  2020-11-23            #SBIN ABOVE 241.5 SL 239.95 TGT 244/246\n",
            "43  2020-11-23  #SBIN #artzteam Support and resistance Please ...\n",
            "44  2020-11-23  #GraphiteIndia \\n#sbin\\n few seconds trade\\nCa...\n",
            "45  2020-11-23  State Bank India day high is 246.15. waiting f...\n",
            "46  2020-11-23  #SBIN long only above 247 ... #frontpage_app h...\n",
            "47  2020-11-22  #sbin enters into MOU\\nWith Luxembourg stock e...\n",
            "48  2020-11-22  #SBIN - State Bank 15Min Chart For intraday - ...\n",
            "49  2020-11-22  RT @market_cafe1: Market Cafe Telegram BOT htt...\n",
            "50  2020-11-22  SBIN still looking positive.\\n\\nRally likely t...\n",
            "51  2020-11-22  #SBIN #EXPIRY Call &amp; #POSITIONAL Call\\n#Ni...\n",
            "52  2020-11-22  #SBIN - I think there will be resistance aroun...\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly2ayoQLAggv",
        "outputId": "a88b92cb-ece5-441f-8d14-4ec3aa2e7e80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Date      object\n",
            "Tweets    object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "data.to_csv(\"Tweets.csv\")\n",
        "cdata=pd.DataFrame(columns=['Date','Tweets'])\n",
        "total=100\n",
        "index=0\n",
        "for index,row in data.iterrows():\n",
        "    stre=row[\"Tweets\"]\n",
        "    my_new_string = re.sub('[^ a-zA-Z0-9]', '', stre)\n",
        "    cdata.sort_index()\n",
        "    cdata.at[index,'Date']=row[\"Date\"]\n",
        "    #cdata.set_value(index,'Date',row[\"Date\"])\n",
        "    cdata.at[index,'Tweets']=my_new_string\n",
        "    #cdata.set_value(index,'Tweets',my_new_string)\n",
        "    index=index+1\n",
        "print(cdata.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ewN-g3AKAggw",
        "outputId": "850d8ad2-6373-4870-ebe5-695b8aba782c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>Love hearing this everyday before the trading ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>Superbb calls provided by my mentor CArajievv ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>Today except sbin my regular trade and nifty 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>shailbhatnagar CNBCAwaaz CNBCBajar hemantghai ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>Buy 2 CURMON SBIN contracts at 24295 Sell 3 CU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>Buy 2 CURMON SBIN contracts at 24295 Sell 3 CU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>RT mohitmaxmoh SBIN CMP 2441 Tommorow is weekl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>SBIN CMP 2441 Tommorow is weekly close and als...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>SBIN CMP 2434 Reversing on hourly charts https...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>SBIN  EQBuy Above24700with SL Below24100For Tg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>RT shivaji1983 Similarities between 2014 amp 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBIN Luxury car maker MercedesBenz India has t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>Booked profit in banknifty and nifty Rest all ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>Buy 1 CURMON SBIN contracts at 24245 Sell 2 CU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>investment  SHORT TERM NSEBUY SBIN cmp 245240 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBINHigh for this series253Rollover httpstcooX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBIN out at 2465LiveTrades Intraday DayTrading</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBINSBIN in Moving in Bharti way158 gtgtgtgt 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBINSBIN in Moving in Bharti way158 gtgtgtgt 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBIN short at 2446LiveTrades Intraday DayTrading</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBIN exit 2461LiveTrades Intraday DayTrading</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBIN shorted at 2452LiveTrades Intraday DayTra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>Ok SBIN moving nowLiveTrades Intraday DayTrading</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>sbinToday giving nice swing both sideNo need o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>Buy 1 CURMON SBIN contracts at 24345 Sell 2 CU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBIN  SBIN LONG  TradingView  httpstcoiPcsVO0uAM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>State Bank India target has been reached Short...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBIN Delivery Buy Call Cmp          2485Target...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>Nifty50 trade above 13100 Nifty Bank 30000 in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBIN RBLBANK IBULHSGFIN BULLISH BUY IN DIPS fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>SBIN  Another trade of the day  PriceAction Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>PSU Banks Ignored in this  Uptrend rally but I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>RT shivaji1983 Similarities between 2014 amp 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>sbin too confirms buy signal 243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>Top 7 Banks in India Follow us on iifsindiaInd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>Buy 9 CURMON BANKBARODA contracts at 46 Sell 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>Do u agree for broad based stocks rally relian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>Buy 9 CURMON BANKBARODA contracts at 4595 Sell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>Huge Up move possible in coming days positiona...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>RT TechnomanThe SBI Apprentice Recruitment 202...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>State Bank Of India Now on Wave C   SBIN chart...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>SBIN amp Axis closed  httpstcoyt1Xt0rg2P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>SBIN ABOVE 2415 SL 23995 TGT 244246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>SBIN artzteam Support and resistance Please pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>GraphiteIndia sbin few seconds tradeCash ac up...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>State Bank India day high is 24615 waiting for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>SBIN long only above 247  frontpageapp httpstc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2020-11-22</td>\n",
              "      <td>sbin enters into MOUWith Luxembourg stock exch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>2020-11-22</td>\n",
              "      <td>SBIN  State Bank 15Min Chart For intraday  Tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2020-11-22</td>\n",
              "      <td>RT marketcafe1 Market Cafe Telegram BOT httpst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>2020-11-22</td>\n",
              "      <td>SBIN still looking positiveRally likely to rem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>2020-11-22</td>\n",
              "      <td>SBIN EXPIRY Call amp POSITIONAL CallNifty Opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>2020-11-22</td>\n",
              "      <td>SBIN  I think there will be resistance around ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Date                                             Tweets\n",
              "0   2020-11-26  Love hearing this everyday before the trading ...\n",
              "1   2020-11-26  Superbb calls provided by my mentor CArajievv ...\n",
              "2   2020-11-26  Today except sbin my regular trade and nifty 1...\n",
              "3   2020-11-26  shailbhatnagar CNBCAwaaz CNBCBajar hemantghai ...\n",
              "4   2020-11-26  Buy 2 CURMON SBIN contracts at 24295 Sell 3 CU...\n",
              "5   2020-11-26  Buy 2 CURMON SBIN contracts at 24295 Sell 3 CU...\n",
              "6   2020-11-26  RT mohitmaxmoh SBIN CMP 2441 Tommorow is weekl...\n",
              "7   2020-11-26  SBIN CMP 2441 Tommorow is weekly close and als...\n",
              "8   2020-11-26  SBIN CMP 2434 Reversing on hourly charts https...\n",
              "9   2020-11-26  SBIN  EQBuy Above24700with SL Below24100For Tg...\n",
              "10  2020-11-26  RT shivaji1983 Similarities between 2014 amp 2...\n",
              "11  2020-11-25  SBIN Luxury car maker MercedesBenz India has t...\n",
              "12  2020-11-25  Booked profit in banknifty and nifty Rest all ...\n",
              "13  2020-11-25  Buy 1 CURMON SBIN contracts at 24245 Sell 2 CU...\n",
              "14  2020-11-25  investment  SHORT TERM NSEBUY SBIN cmp 245240 ...\n",
              "15  2020-11-25  SBINHigh for this series253Rollover httpstcooX...\n",
              "16  2020-11-25     SBIN out at 2465LiveTrades Intraday DayTrading\n",
              "17  2020-11-25  SBINSBIN in Moving in Bharti way158 gtgtgtgt 2...\n",
              "18  2020-11-25  SBINSBIN in Moving in Bharti way158 gtgtgtgt 2...\n",
              "19  2020-11-25   SBIN short at 2446LiveTrades Intraday DayTrading\n",
              "20  2020-11-25       SBIN exit 2461LiveTrades Intraday DayTrading\n",
              "21  2020-11-25  SBIN shorted at 2452LiveTrades Intraday DayTra...\n",
              "22  2020-11-25   Ok SBIN moving nowLiveTrades Intraday DayTrading\n",
              "23  2020-11-25  sbinToday giving nice swing both sideNo need o...\n",
              "24  2020-11-25  Buy 1 CURMON SBIN contracts at 24345 Sell 2 CU...\n",
              "25  2020-11-25   SBIN  SBIN LONG  TradingView  httpstcoiPcsVO0uAM\n",
              "26  2020-11-25  State Bank India target has been reached Short...\n",
              "27  2020-11-25  SBIN Delivery Buy Call Cmp          2485Target...\n",
              "28  2020-11-25  Nifty50 trade above 13100 Nifty Bank 30000 in ...\n",
              "29  2020-11-25  SBIN RBLBANK IBULHSGFIN BULLISH BUY IN DIPS fr...\n",
              "30  2020-11-24  SBIN  Another trade of the day  PriceAction Tr...\n",
              "31  2020-11-24  PSU Banks Ignored in this  Uptrend rally but I...\n",
              "32  2020-11-24  RT shivaji1983 Similarities between 2014 amp 2...\n",
              "33  2020-11-24                   sbin too confirms buy signal 243\n",
              "34  2020-11-24  Top 7 Banks in India Follow us on iifsindiaInd...\n",
              "35  2020-11-24  Buy 9 CURMON BANKBARODA contracts at 46 Sell 4...\n",
              "36  2020-11-24  Do u agree for broad based stocks rally relian...\n",
              "37  2020-11-24  Buy 9 CURMON BANKBARODA contracts at 4595 Sell...\n",
              "38  2020-11-24  Huge Up move possible in coming days positiona...\n",
              "39  2020-11-23  RT TechnomanThe SBI Apprentice Recruitment 202...\n",
              "40  2020-11-23  State Bank Of India Now on Wave C   SBIN chart...\n",
              "41  2020-11-23           SBIN amp Axis closed  httpstcoyt1Xt0rg2P\n",
              "42  2020-11-23                SBIN ABOVE 2415 SL 23995 TGT 244246\n",
              "43  2020-11-23  SBIN artzteam Support and resistance Please pl...\n",
              "44  2020-11-23  GraphiteIndia sbin few seconds tradeCash ac up...\n",
              "45  2020-11-23  State Bank India day high is 24615 waiting for...\n",
              "46  2020-11-23  SBIN long only above 247  frontpageapp httpstc...\n",
              "47  2020-11-22  sbin enters into MOUWith Luxembourg stock exch...\n",
              "48  2020-11-22  SBIN  State Bank 15Min Chart For intraday  Tra...\n",
              "49  2020-11-22  RT marketcafe1 Market Cafe Telegram BOT httpst...\n",
              "50  2020-11-22  SBIN still looking positiveRally likely to rem...\n",
              "51  2020-11-22  SBIN EXPIRY Call amp POSITIONAL CallNifty Opti...\n",
              "52  2020-11-22  SBIN  I think there will be resistance around ..."
            ]
          },
          "execution_count": 418,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWI7KbkcAggx"
      },
      "outputs": [],
      "source": [
        "ccdata=pd.DataFrame(columns=['Date','Tweets'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbARg915Aggy"
      },
      "outputs": [],
      "source": [
        "indx=0\n",
        "get_tweet=\"\"\n",
        "for i in range(0,len(cdata)-1):\n",
        "    get_date=cdata.Date.iloc[i]\n",
        "    next_date=cdata.Date.iloc[i+1]\n",
        "    if(str(get_date)==str(next_date)):\n",
        "        get_tweet=get_tweet+cdata.Tweets.iloc[i]+\" \"\n",
        "    if(str(get_date)!=str(next_date)):\n",
        "        ccdata.at[indx,'Date']=get_date\n",
        "        ccdata.at[indx,'Tweets']=get_tweet\n",
        "        indx=indx+1\n",
        "        get_tweet=\" \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "WCw8cv2GAggz",
        "outputId": "62d100f8-4500-4cfe-f734-014fa5f6e84c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>Love hearing this everyday before the trading ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBIN Luxury car maker MercedesBenz India has ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>SBIN  Another trade of the day  PriceAction T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>RT TechnomanThe SBI Apprentice Recruitment 20...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date                                             Tweets\n",
              "0  2020-11-26  Love hearing this everyday before the trading ...\n",
              "1  2020-11-25   SBIN Luxury car maker MercedesBenz India has ...\n",
              "2  2020-11-24   SBIN  Another trade of the day  PriceAction T...\n",
              "3  2020-11-23   RT TechnomanThe SBI Apprentice Recruitment 20..."
            ]
          },
          "execution_count": 421,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ccdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0Fmc4mVBJ6x",
        "outputId": "28a4865d-b169-45fa-a506-81916ee764f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTOBUhYhCdp_",
        "outputId": "46648c35-5af7-468a-9898-1372abfd3aad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Data_science/Input/AXISBANK.csv\n",
            "/content/drive/My Drive/Data_science/Input/INDUSINDBK (2).csv\n",
            "/content/drive/My Drive/Data_science/Input/NIFTY50_all (1).csv\n",
            "/content/drive/My Drive/Data_science/Input/BRITANNIA.csv\n",
            "/content/drive/My Drive/Data_science/Input/INDUSINDBK (1).csv\n",
            "/content/drive/My Drive/Data_science/Input/INDUSINDBK.csv\n",
            "/content/drive/My Drive/Data_science/Input/VEDL.csv\n",
            "/content/drive/My Drive/Data_science/Input/UPL.csv\n",
            "/content/drive/My Drive/Data_science/Input/TATASTEEL.csv\n",
            "/content/drive/My Drive/Data_science/Input/POWERGRID (1) (1).csv\n",
            "/content/drive/My Drive/Data_science/Input/TCS.csv\n",
            "/content/drive/My Drive/Data_science/Input/POWERGRID (1).csv\n",
            "/content/drive/My Drive/Data_science/Input/POWERGRID.csv\n",
            "/content/drive/My Drive/Data_science/Input/stock_metadata.csv\n",
            "/content/drive/My Drive/Data_science/Input/BAJAJFINSV.csv\n",
            "/content/drive/My Drive/Data_science/Input/BHARTIARTL.csv\n",
            "/content/drive/My Drive/Data_science/Input/TECHM.csv\n",
            "/content/drive/My Drive/Data_science/Input/ITC.csv\n",
            "/content/drive/My Drive/Data_science/Input/EICHERMOT.csv\n",
            "/content/drive/My Drive/Data_science/Input/NESTLEIND.csv\n",
            "/content/drive/My Drive/Data_science/Input/MARUTI.csv\n",
            "/content/drive/My Drive/Data_science/Input/JSWSTEEL.csv\n",
            "/content/drive/My Drive/Data_science/Input/INFY.csv\n",
            "/content/drive/My Drive/Data_science/Input/MM.csv\n",
            "/content/drive/My Drive/Data_science/Input/INFRATEL.csv\n",
            "/content/drive/My Drive/Data_science/Input/ADANIPORTS.csv\n",
            "/content/drive/My Drive/Data_science/Input/BAJAJ-AUTO.csv\n",
            "/content/drive/My Drive/Data_science/Input/NTPC.csv\n",
            "/content/drive/My Drive/Data_science/Input/LT.csv\n",
            "/content/drive/My Drive/Data_science/Input/TATAMOTORS.csv\n",
            "/content/drive/My Drive/Data_science/Input/SBIN.csv\n",
            "/content/drive/My Drive/Data_science/Input/ULTRACEMCO.csv\n",
            "/content/drive/My Drive/Data_science/Input/WIPRO.csv\n",
            "/content/drive/My Drive/Data_science/Input/ICICIBANK.csv\n",
            "/content/drive/My Drive/Data_science/Input/HINDALCO.csv\n",
            "/content/drive/My Drive/Data_science/Input/BPCL.csv\n",
            "/content/drive/My Drive/Data_science/Input/RELIANCE.csv\n",
            "/content/drive/My Drive/Data_science/Input/BAJFINANCE.csv\n",
            "/content/drive/My Drive/Data_science/Input/CIPLA.csv\n",
            "/content/drive/My Drive/Data_science/Input/ONGC.csv\n",
            "/content/drive/My Drive/Data_science/Input/HINDUNILVR.csv\n",
            "/content/drive/My Drive/Data_science/Input/HEROMOTOCO.csv\n",
            "/content/drive/My Drive/Data_science/Input/SUNPHARMA.csv\n",
            "/content/drive/My Drive/Data_science/Input/GAIL.csv\n",
            "/content/drive/My Drive/Data_science/Input/GRASIM.csv\n",
            "/content/drive/My Drive/Data_science/Input/COALINDIA.csv\n",
            "/content/drive/My Drive/Data_science/Input/TITAN.csv\n",
            "/content/drive/My Drive/Data_science/Input/IOC.csv\n",
            "/content/drive/My Drive/Data_science/Input/HDFCBANK.csv\n",
            "/content/drive/My Drive/Data_science/Input/HCLTECH.csv\n",
            "/content/drive/My Drive/Data_science/Input/ZEEL.csv\n",
            "/content/drive/My Drive/Data_science/Input/ASIANPAINT.csv\n",
            "/content/drive/My Drive/Data_science/Input/HDFC.csv\n",
            "/content/drive/My Drive/Data_science/Input/DRREDDY.csv\n",
            "/content/drive/My Drive/Data_science/Input/KOTAKBANK.csv\n",
            "/content/drive/My Drive/Data_science/Input/SHREECEM.csv\n",
            "/content/drive/My Drive/Data_science/Input/NIFTY50_all.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "data = '/content/drive/My Drive/Data_science/Input'\n",
        "for dirname, _, filenames in os.walk(data):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx1oJ7zECXzS"
      },
      "outputs": [],
      "source": [
        "data = '/content/drive/My Drive/Data_science/SBIN30.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KImSfppBnqB"
      },
      "source": [
        "Any stock dataset you want to add in the website can be taken from the website given above then traing the model on that dataset .\n",
        "The dataset is tanken from https://in.finance.yahoo.com/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PagJW0z3Aggz",
        "outputId": "f98c95f1-fb75-4c94-e3e2-0d93497f7c43"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-12-02</td>\n",
              "      <td>343.899994</td>\n",
              "      <td>344.350006</td>\n",
              "      <td>336.200012</td>\n",
              "      <td>338.500000</td>\n",
              "      <td>338.500000</td>\n",
              "      <td>20648850.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-12-03</td>\n",
              "      <td>341.000000</td>\n",
              "      <td>342.950012</td>\n",
              "      <td>333.350006</td>\n",
              "      <td>336.250000</td>\n",
              "      <td>336.250000</td>\n",
              "      <td>26482178.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-12-04</td>\n",
              "      <td>334.100006</td>\n",
              "      <td>342.950012</td>\n",
              "      <td>331.850006</td>\n",
              "      <td>341.850006</td>\n",
              "      <td>341.850006</td>\n",
              "      <td>26789483.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-12-05</td>\n",
              "      <td>343.000000</td>\n",
              "      <td>344.600006</td>\n",
              "      <td>335.149994</td>\n",
              "      <td>336.200012</td>\n",
              "      <td>336.200012</td>\n",
              "      <td>30429507.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-12-06</td>\n",
              "      <td>336.700012</td>\n",
              "      <td>337.649994</td>\n",
              "      <td>318.000000</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>47027528.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>243.500000</td>\n",
              "      <td>246.149994</td>\n",
              "      <td>238.100006</td>\n",
              "      <td>238.699997</td>\n",
              "      <td>238.699997</td>\n",
              "      <td>57538324.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>240.500000</td>\n",
              "      <td>245.000000</td>\n",
              "      <td>239.500000</td>\n",
              "      <td>243.850006</td>\n",
              "      <td>243.850006</td>\n",
              "      <td>47636611.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>245.449997</td>\n",
              "      <td>249.899994</td>\n",
              "      <td>241.600006</td>\n",
              "      <td>243.000000</td>\n",
              "      <td>243.000000</td>\n",
              "      <td>74767232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>244.000000</td>\n",
              "      <td>246.250000</td>\n",
              "      <td>240.149994</td>\n",
              "      <td>245.449997</td>\n",
              "      <td>245.449997</td>\n",
              "      <td>64248318.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>2020-11-27</td>\n",
              "      <td>245.449997</td>\n",
              "      <td>246.250000</td>\n",
              "      <td>242.050003</td>\n",
              "      <td>244.250000</td>\n",
              "      <td>244.250000</td>\n",
              "      <td>54355703.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date        Open        High  ...       Close   Adj Close      Volume\n",
              "0    2019-12-02  343.899994  344.350006  ...  338.500000  338.500000  20648850.0\n",
              "1    2019-12-03  341.000000  342.950012  ...  336.250000  336.250000  26482178.0\n",
              "2    2019-12-04  334.100006  342.950012  ...  341.850006  341.850006  26789483.0\n",
              "3    2019-12-05  343.000000  344.600006  ...  336.200012  336.200012  30429507.0\n",
              "4    2019-12-06  336.700012  337.649994  ...  320.000000  320.000000  47027528.0\n",
              "..          ...         ...         ...  ...         ...         ...         ...\n",
              "245  2020-11-23  243.500000  246.149994  ...  238.699997  238.699997  57538324.0\n",
              "246  2020-11-24  240.500000  245.000000  ...  243.850006  243.850006  47636611.0\n",
              "247  2020-11-25  245.449997  249.899994  ...  243.000000  243.000000  74767232.0\n",
              "248  2020-11-26  244.000000  246.250000  ...  245.449997  245.449997  64248318.0\n",
              "249  2020-11-27  245.449997  246.250000  ...  244.250000  244.250000  54355703.0\n",
              "\n",
              "[250 rows x 7 columns]"
            ]
          },
          "execution_count": 425,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_stock_p=pd.read_csv(data)\n",
        "read_stock_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKjdgJdhAgg0"
      },
      "outputs": [],
      "source": [
        "ccdata['Prices']=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWcxFo6BAgg0",
        "outputId": "a1dac9c5-7995-4c38-d23c-4efeb04c72fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2020-11-26   2020-11-26\n",
            "2020-11-25   2020-11-25\n",
            "2020-11-24   2020-11-24\n",
            "2020-11-23   2020-11-23\n"
          ]
        }
      ],
      "source": [
        "indx=0\n",
        "for i in range (0,len(ccdata)):\n",
        "    for j in range (0,len(read_stock_p)):\n",
        "        get_tweet_date=ccdata.Date.iloc[i]\n",
        "        get_stock_date=read_stock_p.Date.iloc[j]\n",
        "        if(str(get_stock_date)==str(get_tweet_date)):\n",
        "            print(get_stock_date,\" \",get_tweet_date)\n",
        "            ccdata.at[i,'Prices']=int(read_stock_p.Close[j])\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Fp-edtktAgg0",
        "outputId": "48e61c1d-914f-42e3-e56a-ea048ad6cdfc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Prices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-11-26</td>\n",
              "      <td>Love hearing this everyday before the trading ...</td>\n",
              "      <td>245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-11-25</td>\n",
              "      <td>SBIN Luxury car maker MercedesBenz India has ...</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-11-24</td>\n",
              "      <td>SBIN  Another trade of the day  PriceAction T...</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>RT TechnomanThe SBI Apprentice Recruitment 20...</td>\n",
              "      <td>238</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date                                             Tweets Prices\n",
              "0  2020-11-26  Love hearing this everyday before the trading ...    245\n",
              "1  2020-11-25   SBIN Luxury car maker MercedesBenz India has ...    243\n",
              "2  2020-11-24   SBIN  Another trade of the day  PriceAction T...    243\n",
              "3  2020-11-23   RT TechnomanThe SBI Apprentice Recruitment 20...    238"
            ]
          },
          "execution_count": 428,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ccdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "LccdoSiBAgg1",
        "outputId": "46008191-154a-4174-8f15-e03851973a4b"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-429-e1f6ce83edff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mccdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mccdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mccdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5133\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5134\u001b[0m         ):\n\u001b[0;32m-> 5135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
          ]
        }
      ],
      "source": [
        "ccdata=ccdata[ccdata['Prices'].str.strip().astype(bool)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGB0KqbEAgg1"
      },
      "outputs": [],
      "source": [
        "ccdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAm_ISGFAgg1"
      },
      "outputs": [],
      "source": [
        "ccdata['Prices'] = ccdata['Prices'].apply(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPl950BzAgg1"
      },
      "outputs": [],
      "source": [
        "ccdata[\"Comp\"] = ''\n",
        "ccdata[\"Negative\"] = ''\n",
        "ccdata[\"Neutral\"] = ''\n",
        "ccdata[\"Positive\"] = ''\n",
        "ccdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlnL_nf2Agg1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.downloader.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import unicodedata\n",
        "sentiment_i_a = SentimentIntensityAnalyzer()\n",
        "for indexx, row in ccdata.T.iteritems():\n",
        "    try:\n",
        "        sentence_i = unicodedata.normalize('NFKD', ccdata.loc[indexx, 'Tweets'])\n",
        "        sentence_sentiment = sentiment_i_a.polarity_scores(sentence_i)\n",
        "        ccdata.at[indexx,'Comp']=sentence_sentiment['compound']\n",
        "        ccdata.at[indexx,'Negative']=sentence_sentiment['neg']\n",
        "        ccdata.at[indexx,'Neutral']=sentence_sentiment['neu']\n",
        "        ccdata.at[indexx,'Positive']=sentence_sentiment['pos']\n",
        "        if sentence_sentiment['neg']>0.015:\n",
        "            ccdata.at[indexx,'Senti']=-1\n",
        "        elif sentence_sentiment['pos']>0.1:\n",
        "            ccdata.at[indexx,'Senti']=1\n",
        "        else:\n",
        "            ccdata.at[indexx,'Senti']=0\n",
        "    except TypeError:\n",
        "        print (stocks_dataf.loc[indexx, 'Tweets'])\n",
        "        print (indexx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AvPX5ELAgg2"
      },
      "outputs": [],
      "source": [
        "ccdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IBdfzMJAgg2"
      },
      "outputs": [],
      "source": [
        "posi=0\n",
        "nega=0\n",
        "xyz=ccdata['Comp']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muLEmLgyAgg2"
      },
      "outputs": [],
      "source": [
        "print(xyz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eztpj0mXAgg2"
      },
      "outputs": [],
      "source": [
        "xy=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOskPnLwAgg2"
      },
      "outputs": [],
      "source": [
        "for i in ccdata.Senti:\n",
        "    print(i)\n",
        "    get_val=i\n",
        "    if(float(get_val)<0):\n",
        "        nega=nega+1\n",
        "    if(float(get_val)>0):\n",
        "        posi=posi+1\n",
        "    xy=xy+1\n",
        "posper=(posi/(posi+nega))*100\n",
        "negper=(nega/(posi+nega))*100\n",
        "print(\"% of positive tweets= \",posper)\n",
        "print(\"% of negative tweets= \",negper)\n",
        "arr=np.asarray([posper,negper], dtype=int)\n",
        "mlpt.pie(arr,labels=['positive','negative'])\n",
        "mlpt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wH10bG3Agg3"
      },
      "outputs": [],
      "source": [
        "df_=ccdata[['Date','Prices','Comp','Negative','Neutral','Positive']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffzALlJ5Agg3"
      },
      "outputs": [],
      "source": [
        "train_start_index = '0'\n",
        "train_end_index = '6'\n",
        "test_start_index = '7'\n",
        "test_end_index = '9'\n",
        "train = df_.loc[train_start_index : train_end_index]\n",
        "test = df_.loc[test_start_index:test_end_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ersDMR3Agg3"
      },
      "outputs": [],
      "source": [
        "sentiment_score_list = []\n",
        "for date, row in train.T.iteritems():\n",
        "    sentiment_score = np.asarray([df_.loc[date, 'Negative'],df_.loc[date, 'Positive']])\n",
        "    sentiment_score_list.append(sentiment_score)\n",
        "numpy_df_train = np.asarray(sentiment_score_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va4jpKc3Agg3"
      },
      "outputs": [],
      "source": [
        "print(numpy_df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kixtUh5Agg3"
      },
      "outputs": [],
      "source": [
        "sentiment_score_list = []\n",
        "for date, row in test.T.iteritems():\n",
        "    sentiment_score = np.asarray([df_.loc[date, 'Negative'],df_.loc[date, 'Positive']])\n",
        "    sentiment_score_list.append(sentiment_score)\n",
        "numpy_df_test = np.asarray(sentiment_score_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuaYGvjv56wZ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7zJRlAJAgg3"
      },
      "outputs": [],
      "source": [
        "print(numpy_df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rALRXnCuAgg3"
      },
      "outputs": [],
      "source": [
        "y_train = pd.DataFrame(train['Prices'])\n",
        "y_test = pd.DataFrame(test['Prices'])\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDPULNmHvlGX"
      },
      "outputs": [],
      "source": [
        "!pip install treeinterpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QVNElQnAgg3"
      },
      "outputs": [],
      "source": [
        "from treeinterpreter import treeinterpreter as ti\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(numpy_df_train, y_train)\n",
        "prediction, bias, contributions = ti.predict(rf, numpy_df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHNHOwnRAgg4"
      },
      "outputs": [],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yQABvFWAgg4"
      },
      "outputs": [],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3dmoufVAgg4"
      },
      "outputs": [],
      "source": [
        "idx=np.arange(int(test_start_index)-2,int(test_end_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0Kn9p5eAgg4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRZf5stvAgg4"
      },
      "outputs": [],
      "source": [
        "predictions_df_ = pd.DataFrame(data=prediction[:], index = idx, columns=['Prices'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPcou6lEAgg4"
      },
      "outputs": [],
      "source": [
        "predictions_df_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68hlLVjEAgg5"
      },
      "outputs": [],
      "source": [
        "ax = predictions_df_.rename(columns={\"Prices\": \"predicted_price\"}).plot(title='Random Forest predicted prices')#predicted value\n",
        "ax.set_xlabel(\"Indexes\")\n",
        "ax.set_ylabel(\"Stock Prices\")\n",
        "fig = y_test.rename(columns={\"Prices\": \"actual_price\"}).plot(ax = ax).get_figure()#actual value\n",
        "fig.savefig(\"random forest.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3Qgxw75Agg5"
      },
      "outputs": [],
      "source": [
        "from treeinterpreter import treeinterpreter as ti\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(numpy_df_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmJK_NSZAgg5"
      },
      "outputs": [],
      "source": [
        "reg.predict(numpy_df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ckjt6EW6Agg5"
      },
      "outputs": [],
      "source": [
        "'''Since our dataset is very small and as you can see that \n",
        "fetching 600 tweets could only make data for just 3-10 days.\n",
        "Also the prediction is not very great in such small dataset. \n",
        "So we found this new dataset on internet which has the Text as \"Tweets\"\n",
        "and respective \"close price\" and \"Adjusted close price\".\n",
        "Adjusted Close Price: An adjusted closing price is a stock's \n",
        "closing price on any given day of trading that has been amended to \n",
        "include any distributions and corporate actions that occurred at any \n",
        "time before the next day's open.'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "stock_sentiment_with_limits.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
